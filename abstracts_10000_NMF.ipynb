{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF Decomposition and Association Rule Mining\n",
    "This factorization can be used for example for dimensionality reduction, source separation or topic extraction. Association Rule Mining helps us find frequently occuring itemsets (in our case, topics) and characterizes these frequent itemsets with commonly used measures of support, confidence, and lift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and establishing SQLite database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime as datetime\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect(\"testDB.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data using SQL style querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract=pd.read_sql_query(\"select doi,abstract from trial_10000;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1371/journal.pone.0000100</td>\n",
       "      <td>BackgroundMeasuring perceptual judgments about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1371/journal.pone.0000008</td>\n",
       "      <td>Background“Explosive” adaptive radiations on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1371/journal.pone.0000061</td>\n",
       "      <td>Reliable and comprehensive maps of molecular p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1371/journal.pone.0000094</td>\n",
       "      <td>The transcriptional response to exogenously su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1371/journal.pone.0000011</td>\n",
       "      <td>BackgroundDrug treatment is becoming more expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doi  \\\n",
       "0  10.1371/journal.pone.0000100   \n",
       "1  10.1371/journal.pone.0000008   \n",
       "2  10.1371/journal.pone.0000061   \n",
       "3  10.1371/journal.pone.0000094   \n",
       "4  10.1371/journal.pone.0000011   \n",
       "\n",
       "                                            abstract  \n",
       "0  BackgroundMeasuring perceptual judgments about...  \n",
       "1  Background“Explosive” adaptive radiations on i...  \n",
       "2  Reliable and comprehensive maps of molecular p...  \n",
       "3  The transcriptional response to exogenously su...  \n",
       "4  BackgroundDrug treatment is becoming more expe...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract['abstract']=abstract['abstract'].str.replace('\\d+', '') # for digits\n",
    "abstract['abstract']=abstract['abstract'].str.replace(r'(\\b\\w{1,2}\\b)', '') # for words\n",
    "abstract['abstract']=abstract['abstract'].str.replace('Background', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1371/journal.pone.0000100</td>\n",
       "      <td>Measuring perceptual judgments about stimuli w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1371/journal.pone.0000008</td>\n",
       "      <td>“Explosive” adaptive radiations  islands remai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1371/journal.pone.0000061</td>\n",
       "      <td>Reliable and comprehensive maps  molecular pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1371/journal.pone.0000094</td>\n",
       "      <td>The transcriptional response  exogenously supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1371/journal.pone.0000011</td>\n",
       "      <td>Drug treatment  becoming more expensive due  t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            doi  \\\n",
       "0  10.1371/journal.pone.0000100   \n",
       "1  10.1371/journal.pone.0000008   \n",
       "2  10.1371/journal.pone.0000061   \n",
       "3  10.1371/journal.pone.0000094   \n",
       "4  10.1371/journal.pone.0000011   \n",
       "\n",
       "                                            abstract  \n",
       "0  Measuring perceptual judgments about stimuli w...  \n",
       "1  “Explosive” adaptive radiations  islands remai...  \n",
       "2  Reliable and comprehensive maps  molecular pat...  \n",
       "3  The transcriptional response  exogenously supp...  \n",
       "4  Drug treatment  becoming more expensive due  t...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk.stem\n",
    "\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "vectorizer_s = StemmedCountVectorizer(min_df=3, analyzer=\"word\", stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StemmedCountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "            dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "            lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "            ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "            strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "            tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_s.fit(abstract['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aaa', 'aac', 'aag', 'aav']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_s.get_feature_names()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer_s.fit_transform(abstract['abstract']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = np.array(vectorizer_s.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12862)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12862"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics = 50\n",
    "num_top_words = 10\n",
    "clf = decomposition.NMF(n_components=num_topics, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doctopic = clf.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_words = []\n",
    "\n",
    "for topic in clf.components_:\n",
    "    word_idx = np.argsort(topic)[::-1][0:num_top_words]\n",
    "    topic_words.append([vocab[i] for i in word_idx])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "doctopic = doctopic / np.sum(doctopic, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_names=np.asarray(abstract['doi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1371/journal.pone.0000100' '10.1371/journal.pone.0000008'\n",
      " '10.1371/journal.pone.0000061' ..., '10.1371/journal.pone.0009760'\n",
      " '10.1371/journal.pone.0009675' '10.1371/journal.pone.0009654']\n"
     ]
    }
   ],
   "source": [
    "print(doc_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doctopic_orig = doctopic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_groups = len(set(doc_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doctopic_grouped = np.zeros((num_groups, num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(sorted(set(doc_names))):\n",
    "    doctopic_grouped[i, :] = np.mean(doctopic[doc_names == name, :], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plos_articles = sorted(set(doc_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display top 10 topics in a document, and words in a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(doctopic_grouped)):\n",
    "    top_topics = np.argsort(doctopic_grouped[i,:])[::-1][0:10]\n",
    "    top_topics_str = ' '.join(str(t) for t in top_topics)\n",
    "    #print(\"{}: {}\".format(plos_articles[i], top_topics_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: differenti stem cultur marker develop bone tissu embryon progenitor vitro\n",
      "Topic 1: cell line prolifer stem cycl epitheli vivo cultur vitro type\n",
      "Topic 2: gene identifi analysi microarray involv encod cluster profil pathway relat\n",
      "Topic 3: protein membran identifi proteom complex local domain like process encod\n",
      "Topic 4: result role develop suggest mutant play mechan format growth import\n",
      "Topic 5: infect host immun parasit transmiss pathogen hcv viral bacteri tuberculosi\n",
      "Topic 6: associ risk snps genotyp polymorph signific allel variant genet identifi\n",
      "Topic 7: activ phosphoryl kinas inhibit depend enzym stimul mediat erk channel\n",
      "Topic 8: hiv infect viral women aid risk art partner preval prevent\n",
      "Topic 9: tumor cancer breast growth lung line prostat ovarian target progress\n",
      "Topic 10: vaccin immun antibodi antigen protect dose malaria immunogen challeng bcg\n",
      "Topic 11: interact network complex dynam biolog mechan host organ connect understand\n",
      "Topic 12: patient clinic treatment therapi signific outcom analysi compar group blood\n",
      "Topic 13: mice defici mous transgen type wild bone tissu liver tlr\n",
      "Topic 14: respons immun stress ifn tlr antigen inflammatori cytokin innat adapt\n",
      "Topic 15: function structur domain similar import connect loss treg character provid\n",
      "Topic 16: human mous anim tissu chimpanze provid antibodi princip deriv major\n",
      "Topic 17: regul role involv metabol import identifi mediat cycl phosphoryl regulatori\n",
      "Topic 18: model predict dynam paramet experiment base distribut simul structur anim\n",
      "Topic 19: dna methyl damag repair strand replic pcr recombin site cpg\n",
      "Topic 20: signal pathway wnt kinas catenin phosphoryl akt target notch pik\n",
      "Topic 21: express tissu pattern mrna profil microarray normal transgen suggest line\n",
      "Topic 22: sequenc conserv high base similar divers analysi phylogenet code acid\n",
      "Topic 23: mutat mutant type genet wild phenotyp resist caus allel egfr\n",
      "Topic 24: bind structur domain site peptid residu region acid termin conserv\n",
      "Topic 25: diseas progress sever caus infecti inflammatori disord coral prion pathogen\n",
      "Topic 26: popul genet select individu variat size divers region sampl isol\n",
      "Topic 27: studi report show includ previous present result provid review methodolog\n",
      "Topic 28: virus influenza viral replic pandem rna avian host isol season\n",
      "Topic 29: speci plant divers conserv communiti chang relat distribut host rang\n",
      "Topic 30: mirna mir target microrna small develop novel role rnas identifi\n",
      "Topic 31: level high correl plasma low mrna higher signific serum blood\n",
      "Topic 32: effect reduc cost inhibit treatment potenti growth protect affect treat\n",
      "Topic 33: use method detect tool assay base approach identifi imag measur\n",
      "Topic 34: neuron brain synapt rat axon channel neural hippocamp behavior potenti\n",
      "Topic 35: transcript factor promot bind site rna target element region nuclear\n",
      "Topic 36: strain isol type virul pathogen host resist bacteri bacteria adapt\n",
      "Topic 37: male femal mate sexual sex behavior reproduct social genet prefer\n",
      "Topic 38: specif antigen antibodi target peptid detect tissu sensit assay high\n",
      "Topic 39: data method analysi base set predict approach provid inform sampl\n",
      "Topic 40: drug resist treatment target therapi combin new high clinic antibiot\n",
      "Topic 41: control case compar signific group subject intervent healthi non match\n",
      "Topic 42: receptor ligand mediat agonist tlr membran select antagonist stimul surfac\n",
      "Topic 43: induc inhibit apoptosi inflammatori death mechan mediat inflamm depend product\n",
      "Topic 44: increas decreas chang muscl insulin signific metabol glucos stress reduc\n",
      "Topic 45: test posit result negat sensit perform tuberculosi detect sampl case\n",
      "Topic 46: process visual time task brain chang memori relat learn subject\n",
      "Topic 47: genom region chromosom identifi number map genet wide select recombin\n",
      "Topic 48: differ compar signific group type individu variat condit select similar\n",
      "Topic 49: age year group children risk malaria month rate women trial\n"
     ]
    }
   ],
   "source": [
    " for t in range(len(topic_words)):\n",
    "        print(\"Topic {}: {}\".format(t, ' '.join(topic_words[t][:15])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 'Baskets' of topics for each article. \n",
    "Here, article is the identifier, and the collection of topics acts like the shopping basket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket=[]\n",
    "for i in range(len(doctopic_grouped)):\n",
    "    top_topics = np.argsort(doctopic_grouped[i,:])[::-1][0:10]\n",
    "    basket.append(list(top_topics))\n",
    "#print(basket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making use of Apriori algorithm to generate frequent itemsets with threshold as 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "oht = OnehotTransactions()\n",
    "oht_ary = oht.fit(basket).transform(basket)\n",
    "df = pd.DataFrame(oht_ary, columns=oht.columns_)\n",
    "frequent_itemsets = apriori(df, min_support=0.10, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying association rules to generated frequent itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedants</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.531213</td>\n",
       "      <td>1.322084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(7)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.2423</td>\n",
       "      <td>0.518366</td>\n",
       "      <td>1.290109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(21)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.517448</td>\n",
       "      <td>1.287824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(43)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.600633</td>\n",
       "      <td>1.494856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(39)</td>\n",
       "      <td>(33)</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>0.543305</td>\n",
       "      <td>1.240988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(45)</td>\n",
       "      <td>(33)</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.520264</td>\n",
       "      <td>1.188361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(46)</td>\n",
       "      <td>(33)</td>\n",
       "      <td>0.2835</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>1.156979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedants consequents  support  confidence      lift\n",
       "0         (3)         (1)   0.2547    0.531213  1.322084\n",
       "1         (7)         (1)   0.2423    0.518366  1.290109\n",
       "2        (21)         (1)   0.2006    0.517448  1.287824\n",
       "3        (43)         (1)   0.2211    0.600633  1.494856\n",
       "4        (39)        (33)   0.3383    0.543305  1.240988\n",
       "5        (45)        (33)   0.2270    0.520264  1.188361\n",
       "6        (46)        (33)   0.2835    0.506526  1.156979"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
