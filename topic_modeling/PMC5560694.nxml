<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28817592</article-id><article-id pub-id-type="pmc">5560694</article-id><article-id pub-id-type="publisher-id">PONE-D-16-43751</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0182070</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Endocrine System</subject><subj-group><subject>Thyroid</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Endocrine System</subject><subj-group><subject>Thyroid</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Diagnostic Medicine</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Information Technology</subject><subj-group><subject>Data Mining</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Plants</subject><subj-group><subject>Trees</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Hormones</subject><subj-group><subject>Thyroid Hormones</subject><subj-group><subject>Thyroxine</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Hormones</subject><subj-group><subject>Peptide Hormones</subject><subj-group><subject>Thyroid-Stimulating Hormone</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Neural Networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural Networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability Theory</subject><subj-group><subject>Markov Models</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Using <italic>k</italic>-dependence causal forest to mine the most significant dependency relationships among clinical variables for thyroid disease diagnosis</article-title><alt-title alt-title-type="running-head">Using KCF to mine the most significant dependency relationships for thyroid disease diagnosis</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7742-669X</contrib-id><name><surname>Wang</surname><given-names>LiMin</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Cao</surname><given-names>FangYuan</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>ShuangCheng</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Validation</role><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Sun</surname><given-names>MingHui</given-names></name><role content-type="http://credit.casrai.org/">Formal analysis</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Dong</surname><given-names>LiYan</given-names></name><role content-type="http://credit.casrai.org/">Resources</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, ChangChun City 130012, China</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Lixin Accounting Research Institute, Shanghai Lixin University of Commerce, Shanghai City 201620, China</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Bajic</surname><given-names>Vladimir B.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>King Abdullah University of Science and Technology, SAUDI ARABIA</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>smh@jlu.edu.cn</email> (MHS); <email>dongly@jlu.edu.cn</email> (LYD)</corresp></author-notes><pub-date pub-type="collection"><year>2017</year></pub-date><pub-date pub-type="epub"><day>17</day><month>8</month><year>2017</year></pub-date><volume>12</volume><issue>8</issue><elocation-id>e0182070</elocation-id><history><date date-type="received"><day>3</day><month>11</month><year>2016</year></date><date date-type="accepted"><day>12</day><month>7</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; 2017 Wang et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Wang et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0182070.pdf"/><abstract><p>Numerous data mining models have been proposed to construct computer-aided medical expert systems. Bayesian network classifiers (BNCs) are more distinct and understandable than other models. To graphically describe the dependency relationships among clinical variables for thyroid disease diagnosis and ensure the rationality of the diagnosis results, the proposed <italic>k</italic>-dependence causal forest (KCF) model generates a series of submodels in the framework of maximum spanning tree (MST) and demonstrates stronger dependence representation. Friedman test on 12 UCI datasets shows that KCF has classification accuracy advantage over the other state-of-the-art BNCs, such as Naive Bayes, tree augmented Naive Bayes, and <italic>k</italic>-dependence Bayesian classifier. Our extensive experimental comparison on 4 medical datasets also proves the feasibility and effectiveness of KCF in terms of sensitivity and specificity.</p></abstract><funding-group><award-group id="award001"><funding-source><institution-wrap><institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>61272209</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7742-669X</contrib-id><name><surname>Wang</surname><given-names>LiMin</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution>Agreement of Science &#x00026; Technology Development Project, Jilin Province</institution></funding-source><award-id>20150101014JC</award-id></award-group><funding-statement>This work was supported by the National Science Foundation of China (Grant No. 61272209) and the Agreement of Science &#x00026; Technology Development Project, Jilin Province (No. 20150101014JC). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="8"/><table-count count="5"/><page-count count="17"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>We used 12 data sets for experimental study. The URLs for these data sets are different and are listed below, Echocardiogram----------<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Echocardiogram">https://archive.ics.uci.edu/ml/datasets/Echocardiogram</ext-link> Heart----------<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29">https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29</ext-link> Heart Disease---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</ext-link> Chess---------- <ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29">http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29</ext-link> Breast ---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29</ext-link> Pima Indians Diabetes---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</ext-link> Tic-Tac-Toe---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame">https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame</ext-link> German---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29">https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29</ext-link> Spambase---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Spambase">https://archive.ics.uci.edu/ml/datasets/Spambase</ext-link> Mushroom---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Mushroom">https://archive.ics.uci.edu/ml/datasets/Mushroom</ext-link> Adult ---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Adult">https://archive.ics.uci.edu/ml/datasets/Adult</ext-link> Census Income---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Census+Income">https://archive.ics.uci.edu/ml/datasets/Census+Income</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>We used 12 data sets for experimental study. The URLs for these data sets are different and are listed below, Echocardiogram----------<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Echocardiogram">https://archive.ics.uci.edu/ml/datasets/Echocardiogram</ext-link> Heart----------<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29">https://archive.ics.uci.edu/ml/datasets/Statlog+%28Heart%29</ext-link> Heart Disease---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</ext-link> Chess---------- <ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29">http://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King-Pawn%29</ext-link> Breast ---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29">https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29</ext-link> Pima Indians Diabetes---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</ext-link> Tic-Tac-Toe---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame">https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame</ext-link> German---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29">https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29</ext-link> Spambase---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Spambase">https://archive.ics.uci.edu/ml/datasets/Spambase</ext-link> Mushroom---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Mushroom">https://archive.ics.uci.edu/ml/datasets/Mushroom</ext-link> Adult ---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Adult">https://archive.ics.uci.edu/ml/datasets/Adult</ext-link> Census Income---------- <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Census+Income">https://archive.ics.uci.edu/ml/datasets/Census+Income</ext-link>.</p></notes></front><body><sec id="sec001"><title>Background</title><p>Data mining [<xref rid="pone.0182070.ref001" ref-type="bibr">1</xref>] [<xref rid="pone.0182070.ref002" ref-type="bibr">2</xref>] is used to extract unknown but potentially useful information by using available incomplete, noisy, fuzzy, and random practical application data. The medical domain consists of a considerable amount of data, including complete human genetic code information; clinical information on the history of patients, diagnosis, inspection, and treatment; and drug management information. Data mining can be applied in the medical field to analyze medical data, extract implicit valuable information, provide correct diagnosis and treatment, and study the genetic law of human diseases and health [<xref rid="pone.0182070.ref003" ref-type="bibr">3</xref>].</p><p>While dealing with a large amount of historical information of patients in the database, data mining needs to confirm the diagnosis based on age, gender, auxiliary examination results, and physiological and biochemical indicators of patients. Thus, data mining should eliminate interference of human factors and establish diagnosis rules with good universality, provided that large amounts of data are analyzed in the process. Consequently, researchers can establish a prediction model, test it, and construct an accurate algorithmic model, which can be used for diagnosis of clinical medical conditions.</p><p>Now, about 20 million Americans have some form of thyroid disease, and people of all ages and races can have the chance to get thyroid disease [<xref rid="pone.0182070.ref004" ref-type="bibr">4</xref>]. Recently, a fair mount of data mining methods have been investigated to diagnose this kind of disease. To explore the value of contrast-enhanced ultrasound combined with conventional ultrasound in the diagnosis of thyroid microcarcinoma, multivariate logistic regression analysis is performed to determine independent risk factors [<xref rid="pone.0182070.ref005" ref-type="bibr">5</xref>]. Proper interpretation of the thyroid data besides clinical examination and complementary investigation is an important issue, a comparative study of thyroid disease diagnosis is made by using three different types of neural networks, i.e. multilayer neural network, probabilistic neural network and learning vector quantization neural network [<xref rid="pone.0182070.ref006" ref-type="bibr">6</xref>]. An enhanced fuzzy <italic>k</italic>-nearest neighbor (FKNN) classifier based computer aided diagnostic system is presented for thyroid disease [<xref rid="pone.0182070.ref004" ref-type="bibr">4</xref>]. The neighborhood size <italic>k</italic> and the fuzzy strength parameter <italic>m</italic> in FKNN classifier are adaptively specified by the particle swarm optimization approach. The application of Support Vector Machines is proposed to classify thyroid bioptic specimens [<xref rid="pone.0182070.ref007" ref-type="bibr">7</xref>], together with a particular wrapper feature selection algorithm (i.e., recursive feature elimination). The model is able to provide an accurate discriminatory capability using only 20 out of 144 features, resulting in an increase of the model performances, reliability, and computational efficiency. To elucidate the cytological characteristics and the diagnostic usefulness of intraoperative cytology for papillary thyroid carcinoma, decision tree analysis is used to find effective features for accurate cytological diagnosis [<xref rid="pone.0182070.ref008" ref-type="bibr">8</xref>].</p><p>Bayesian method is an intelligent computing method used in reasoning and managing uncertainty problems [<xref rid="pone.0182070.ref009" ref-type="bibr">9</xref>]. BNC is a probability network based on graphical models used to provide probabilistic inference, thus it is more distinct and understandable than other methods. A BNC consists of a structural model and a set of conditional probabilities. The structural model is a directed acyclic graph, in which nodes represent classes <italic>C</italic> and a set of random attributes <bold>X</bold> = (<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>, &#x02026;, <italic>X</italic><sub><italic>n</italic></sub>). Arcs between nodes are used to describe the conditional dependence relationships, which are quantified using conditional probabilities for each node given to the parents. Bayesian methods have gained increasing interest in medical diagnosis. BN and graph theory are used to encode causal relations among variables for diagnosis and predictions in the medical domain [<xref rid="pone.0182070.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0182070.ref012" ref-type="bibr">12</xref>].</p><p>The Markov blanket of a target attribute is the minimal attribute set for explaining the target attribute based on the conditional independence of all the attributes to be connected in a BN [<xref rid="pone.0182070.ref013" ref-type="bibr">13</xref>]. Koller and Sahami [<xref rid="pone.0182070.ref014" ref-type="bibr">14</xref>] defined the Markov blanket of a target attribute as the minimal set of conditioned attributes, in which all other attributes are independent of the target attribute in the probabilistic graphical model. Hence, the Markov blanket of a target attribute removes unnecessary attributes and represents the minimal information for explaining the target attribute. In a BN model, the Markov blanket of <italic>T</italic>, i.e., MB(<italic>T</italic>) is the union of parent, child, and parent of children nodes of <italic>T</italic> [<xref rid="pone.0182070.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0182070.ref015" ref-type="bibr">15</xref>]. For example, in <xref ref-type="fig" rid="pone.0182070.g001">Fig 1</xref>, the parent nodes of <italic>T</italic> are <italic>B</italic> and <italic>C</italic>, the child node of <italic>T</italic> is <italic>F</italic>, and the parent of the children node of <italic>T</italic> is <italic>E</italic>. Thus, the Markov blanket of <italic>T</italic> is MB(<italic>T</italic>) = {<italic>B</italic>, <italic>C</italic>, <italic>F</italic>, <italic>E</italic>}, indicating that nodes <italic>A</italic>, <italic>D</italic>, and <italic>G</italic> are independent of <italic>T</italic> conditioned on MB(<italic>T</italic>).</p><fig id="pone.0182070.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g001</object-id><label>Fig 1</label><caption><title>An example Markov blanket.</title></caption><graphic xlink:href="pone.0182070.g001"/></fig><p>The performance of a classifier is evaluated using two key factors, namely, classification accuracy and space complexity of a model. A BN cannot express all relationships between the attributes and the class. Thus, a trade-off should exist between the structure complexity and classification accuracy. Some restricted Bayesian classifiers, e.g., Naive Bayes (NB), tree augmented Naive Bayes (TAN), and <italic>k</italic>-dependence BNs (KDB), exhibit satisfactory performance for classification at different levels of conditional independence assumption. When carrying out medical analysis, different doctors may consider different factor or attribute as starting point. One BNC is unable to express this diversity. This paper proposes a novel learning algorithm called the <italic>k</italic>-dependence causal forest (KCF). This algorithm generates a series of submodels, which are used to construct classifiers with different root nodes at arbitrary points (values of <italic>k</italic>) along the attribute dependence spectrum. The KCF algorithm aims to describe the significant dependency relationships between root node <italic>X</italic><sub><italic>r</italic></sub> and MB(<italic>X</italic><sub><italic>r</italic></sub>) while simultaneously providing accurate diagnosis to patients with thyroid diseases.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Materials and methods</title><sec id="sec003"><title>Data</title><p>This research work adopts the public thyroid disease dataset from the University of California, Irvine (UCI) Machine Learning Repository [<xref rid="pone.0182070.ref016" ref-type="bibr">16</xref>]. The UCI database currently contains 335 datasets, and the number of sets continuously increases. The thyroid disease dataset was stored in the UCI by Ross Quinlan during his visit in 1987 for the 1987 Machine Learning Workshop; the set contains 9172 real historical instances. Each instance consists of 29 attributes, which can be classified into 20 classes. The characteristics of thyroid disease dataset are multivariate and domain theory, the characteristics of the contained attributes are categorical and real, and the associated task of the dataset is classification.</p></sec><sec id="sec004"><title>Three restricted Bayesian classifiers</title><p>BNs are often used to solve classification problems by constructing classifiers from a given set of training instances with class labels. With high classification accuracy and efficiency, BN classifiers perform outstandingly in a number of classification methods. This paper briefly introduces the three popular restricted Bayesian classifiers. In the following discussion, capital letters, such as <italic>X</italic>, <italic>Y</italic> and <italic>Z</italic>, denote attribute names, and lower-case letters, such as <italic>x</italic>, <italic>y</italic> and <italic>z</italic>, denote the specific values taken by those attributes. Sets of attributes are denoted by boldface capital letters, such as <inline-formula id="pone.0182070.e001"><alternatives><graphic xlink:href="pone.0182070.e001.jpg" id="pone.0182070.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Y</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0182070.e002"><alternatives><graphic xlink:href="pone.0182070.e002.jpg" id="pone.0182070.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:math></alternatives></inline-formula>, and assignments of values to the attributes in these sets are denoted by boldface lowercase letters, such as <bold>x, y</bold> and <bold>z</bold>.</p><p>The NB classifier is the simplest BN model and is very robust [<xref rid="pone.0182070.ref017" ref-type="bibr">17</xref>]. Given the <italic>n</italic> independent attributes <bold>X</bold> = (<italic>X</italic><sub>1</sub>, <italic>X</italic><sub>2</sub>, &#x02026;, <italic>X</italic><sub><italic>n</italic></sub>) and <italic>m</italic> classes <italic>c</italic><sub>1</sub>, <italic>c</italic><sub>2</sub>, &#x02026;, <italic>c</italic><sub><italic>m</italic></sub>, classification will derive the maximum of <italic>P</italic>(<italic>c</italic><sub><italic>i</italic></sub>|<italic>x</italic>), where 1 &#x02264; <italic>i</italic> &#x02264; <italic>m</italic>. Result can be derived from the Bayesian theorem, as <xref ref-type="disp-formula" rid="pone.0182070.e003">Eq (1)</xref> shows:
<disp-formula id="pone.0182070.e003"><alternatives><graphic xlink:href="pone.0182070.e003.jpg" id="pone.0182070.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula></p><p>The rigorous assumption in NB is that all attributes are conditionally independent of each other. Thus, the class assignments of the test samples are based on <xref ref-type="disp-formula" rid="pone.0182070.e004">Eq (2)</xref>.
<disp-formula id="pone.0182070.e004"><alternatives><graphic xlink:href="pone.0182070.e004.jpg" id="pone.0182070.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula></p><p>The basic framework of TAN [<xref rid="pone.0182070.ref018" ref-type="bibr">18</xref>] is the extension of the Chow-Liu tree [<xref rid="pone.0182070.ref019" ref-type="bibr">19</xref>], which utilizes conditional mutual information to build a maximum spanning tree (MST). TAN is a one-dependence classifier because it allows each attribute to have at most one parent in addition to the class. In practice, TAN is regarded as a good trade-off between the model complexity and classification performance. <xref ref-type="fig" rid="pone.0182070.g002">Fig 2</xref> shows an example of the condition mutual information matrix with six attributes and corresponding undirected MST. The selected six attributes are the first few attributes with the maximum mutual information with class <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>C</italic>) in the thyroid disease dataset.</p><fig id="pone.0182070.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g002</object-id><label>Fig 2</label><caption><title>An example of conditional mutual information matrix (a) and corresponding undirected MST (b).</title><p>Attributes {<italic>X</italic><sub>2</sub>, <italic>X</italic><sub>17</sub>, <italic>X</italic><sub>19</sub>, <italic>X</italic><sub>21</sub>, <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>25</sub>} correspond to clinical variables <italic>on thyroxine</italic>, <italic>TSH</italic>, <italic>T3</italic>, <italic>TT4</italic>, <italic>T4U</italic> and <italic>FTI</italic>, respectively.</p></caption><graphic xlink:href="pone.0182070.g002"/></fig><p>For a TAN model, the class assignments of the test samples are based on <xref ref-type="disp-formula" rid="pone.0182070.e005">Eq (3)</xref>.
<disp-formula id="pone.0182070.e005"><alternatives><graphic xlink:href="pone.0182070.e005.jpg" id="pone.0182070.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
where <italic>X</italic><sub><italic>jp</italic></sub> is the parent node of <italic>X</italic><sub><italic>j</italic></sub>.</p><p>After selecting each attribute as the root node and setting the outward direction of all the arcs from the attributes, six different directed MSTs are generated, as shown in <xref ref-type="fig" rid="pone.0182070.g003">Fig 3</xref>. The root node is filled in black. The directed MSTs can be regarded as different representations of the same spectrum of causal relationships under different conditions. One MST corresponds to <italic>n</italic> directed trees, and each tree uses different attributes as the root node. Although TAN can achieve a global one-dependence optimization, MST cannot be extended to arbitrary <italic>k</italic>-dependence structure when <italic>k</italic> &#x0003e; 1.</p><fig id="pone.0182070.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g003</object-id><label>Fig 3</label><caption><title>An example of directed MSTs with different root nodes, which are filled in black.</title><p>Attributes {<italic>X</italic><sub>2</sub>, <italic>X</italic><sub>17</sub>, <italic>X</italic><sub>19</sub>, <italic>X</italic><sub>21</sub>, <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>25</sub>} correspond to clinical variables <italic>on thyroxine</italic>, <italic>TSH</italic>, <italic>T3</italic>, <italic>TT4</italic>, <italic>T4U</italic> and <italic>FTI</italic>, respectively.</p></caption><graphic xlink:href="pone.0182070.g003"/></fig><p>The KDB [<xref rid="pone.0182070.ref020" ref-type="bibr">20</xref>] is a <italic>k</italic>-dependence classifier because it allows each attribute to have a maximum number of <italic>k</italic> parents in addition to the class attribute. Starting with the highest, an attribute order is pre-determined by comparing the mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>C</italic>). By comparing conditional mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>|<italic>C</italic>), each attribute can select a maximum number of <italic>k</italic> parents among the attributes ahead of itself in the pre-determined order.</p><p>For a KDB model, the class assignments of the test samples are based on <xref ref-type="disp-formula" rid="pone.0182070.e006">Eq (4)</xref>.
<disp-formula id="pone.0182070.e006"><alternatives><graphic xlink:href="pone.0182070.e006.jpg" id="pone.0182070.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:munder><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x0220f;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
where {<italic>X</italic><sub><italic>j</italic>1</sub>, &#x022ef;, <italic>X</italic><sub><italic>jp</italic></sub>} are the parent attributes of <italic>X</italic><sub><italic>j</italic></sub> and <italic>p</italic> = <italic>min</italic>(<italic>j</italic> &#x02212; 1, <italic>k</italic>).</p></sec><sec id="sec005"><title>KCF algorithm</title><p>MST contains the most significant relationships among attributes. Thus at training time, we aim to achieve high-dependence directed trees by extending one-dependence directed trees that are inferred from MST. Each one-dependence directed tree is extended to the <italic>k</italic>-dependence conditional tree along the attribute dependence spectrum. Finally, we will obtain a series of <italic>k</italic>-dependence trees rather than one augmented tree. Leaf node <italic>X</italic><sub><italic>i</italic></sub> can be used to select other nodes as parents along the path from <italic>X</italic><sub><italic>i</italic></sub> to the root node by comparing the conditional mutual information. For example, as shown in <xref ref-type="fig" rid="pone.0182070.g003">Fig 3(a)</xref>, <italic>X</italic><sub>2</sub>, <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>25</sub> are the possible parents of <italic>X</italic><sub>17</sub>, and <italic>X</italic><sub>2</sub>, <italic>X</italic><sub>23</sub> are the possible parents of <italic>X</italic><sub>25</sub>. Different root nodes correspond to different spanning trees or Bayesian classifiers, the ensemble of which finally forms a forest. When <italic>k</italic> &#x0003e; 1, e.g., <italic>k</italic> = 2, more parents can be selected for each non-root node by comparing the conditional mutual information. <xref ref-type="fig" rid="pone.0182070.g004">Fig 4</xref> shows the <italic>k</italic>-dependence Bayesian classifiers when <italic>k</italic> = 2. The newly added arcs are annotated with red color.</p><fig id="pone.0182070.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g004</object-id><label>Fig 4</label><caption><title>The KCF (<italic>k</italic> = 2) model corresponding to the MSTs shown in <xref ref-type="fig" rid="pone.0182070.g003">Fig 3</xref>.</title><p>Attributes {<italic>X</italic><sub>2</sub>, <italic>X</italic><sub>17</sub>, <italic>X</italic><sub>19</sub>, <italic>X</italic><sub>21</sub>, <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>25</sub>, <italic>C</italic>} correspond to clinical variables <italic>on thyroid</italic>, <italic>TSH</italic>, <italic>T3</italic>, <italic>TT4</italic>, <italic>T4U</italic>, <italic>FTI</italic> and <italic>Class</italic>, respectively.</p></caption><graphic xlink:href="pone.0182070.g004"/></fig><p>At the testing time, KCF estimates the class membership probabilities by using each subclassifier, and the final result is the average of the outputs of all subclassifiers. The training procedure (KCF-Training) and testing procedure (KCF-Testing) are depicted below.</p><p><bold>Algorithm 1</bold> KCF-Training</p><p specific-use="line"><bold>Input:</bold> Pre-classified instance set DB with <italic>n</italic> predictive attributes {<italic>X</italic><sub>1</sub>, &#x022ef;, <italic>X</italic><sub><italic>n</italic></sub>}.</p><p specific-use="line"><bold>Output:</bold> Subclassifiers {KCF<sub>1</sub>, &#x022ef;, KCF<sub><italic>n</italic></sub> }.</p><p specific-use="line">&#x02003;1: Compute conditional mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>|<italic>C</italic>) for each pair of attributes <italic>X</italic><sub><italic>i</italic></sub> and <italic>X</italic><sub><italic>j</italic></sub>, where <italic>i</italic> &#x02260; <italic>j</italic>.</p><p specific-use="line">&#x02003;2: Build undirected MST by comparing conditional mutual information.</p><p specific-use="line">&#x02003;3: For each attribute <italic>X</italic><sub><italic>i</italic></sub>(<italic>i</italic> = 1, 2, &#x02026;, <italic>n</italic>)</p><p specific-use="line">&#x02003;&#x02003;(a) Transform the MST to be a directed one by choosing <italic>X</italic><sub><italic>i</italic></sub> as the root and setting the direction of all arcs to be outward from it.</p><p specific-use="line">&#x02003;&#x02003;(b) Let the Bayesian subclassifier being constructed, KCF<sub><italic>i</italic></sub>, begin with the directed MST.</p><p specific-use="line">&#x02003;&#x02003;(c) Add a node to KCF<sub><italic>i</italic></sub> representing class variable <italic>C</italic>.</p><p specific-use="line">&#x02003;&#x02003;(d) Add an arc from <italic>C</italic> to each node in KCF<sub><italic>i</italic></sub>.</p><p specific-use="line">&#x02003;&#x02003;(e) For each node <italic>X</italic><sub><italic>j</italic></sub>(<italic>j</italic> &#x02260; <italic>i</italic>), add <italic>m</italic> &#x02212; 1(<italic>m</italic> = <italic>min</italic>(<italic>d</italic>, <italic>k</italic>), <italic>d</italic> is the number of nodes along the branch from root to <italic>X</italic><sub><italic>j</italic></sub>) arcs from <italic>m</italic> &#x02212; 1 distinct attributes <italic>X</italic><sub><italic>P</italic></sub> to <italic>X</italic><sub><italic>j</italic></sub>. <italic>X</italic><sub><italic>P</italic></sub> should locate in the branch from root to <italic>X</italic><sub><italic>j</italic></sub> and correspond to the first <italic>m</italic> &#x02212; 1 highest value for <italic>I</italic>(<italic>X</italic><sub><italic>P</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>|<italic>C</italic>).</p><p specific-use="line">&#x02003;4: Compute the conditional probability tables inferred by the structure of KCF<sub><italic>i</italic></sub> by using counts from <italic>DB</italic>, and output KCF<sub><italic>i</italic></sub>.</p><p><bold>Algorithm 2</bold> KCF-Testing</p><p specific-use="line"><bold>Input:</bold> KCF<sub>1</sub>, KCF<sub>2</sub>, &#x02026;, KCF<sub><italic>n</italic></sub> and a testing instance <italic>e</italic>.</p><p specific-use="line"><bold>Output:</bold> The conditional probabilities <inline-formula id="pone.0182070.e007"><alternatives><graphic xlink:href="pone.0182070.e007.jpg" id="pone.0182070.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>c</italic> is the class label.</p><p specific-use="line">&#x02003;1: For each KCF<sub><italic>i</italic>(<italic>i</italic> = 1, 2, &#x02026;, <italic>n</italic>)</sub>, estimate the conditional probability <inline-formula id="pone.0182070.e008"><alternatives><graphic xlink:href="pone.0182070.e008.jpg" id="pone.0182070.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> that <italic>e</italic> belongs to class <italic>c</italic>.</p><p specific-use="line">&#x02003;2: Average all of the probabilities <inline-formula id="pone.0182070.e009"><alternatives><graphic xlink:href="pone.0182070.e009.jpg" id="pone.0182070.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p><p specific-use="line">&#x02003;3: Return the estimated <inline-formula id="pone.0182070.e010"><alternatives><graphic xlink:href="pone.0182070.e010.jpg" id="pone.0182070.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0182070.e011"><alternatives><graphic xlink:href="pone.0182070.e011.jpg" id="pone.0182070.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, &#x02026;, <inline-formula id="pone.0182070.e012"><alternatives><graphic xlink:href="pone.0182070.e012.jpg" id="pone.0182070.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p><p><italic>k</italic> is related to the classification performance of a high-dependence classifier. An appropriate value of <italic>k</italic> cannot be effectively preselected to achieve the optimal trade-off between the model complexity and classification performance [<xref rid="pone.0182070.ref021" ref-type="bibr">21</xref>]. For each KCF<sub><italic>i</italic></sub>, the space complexity increases exponentially as the value of <italic>k</italic> increases to achieve a trade-off between the classification performance and efficiency. We set <italic>k</italic> = 2 in the following experiments.</p></sec></sec><sec sec-type="results" id="sec006"><title>Results</title><p>The detailed introduction of the 29 attributes from thyroid disease dataset in UCI database is shown in <xref ref-type="table" rid="pone.0182070.t001">Table 1</xref>. And numeric attributes in thyroid disease dataset are discretized by using 10-bin equal frequency discretization. In order to minimize the bias associated with the random sampling of the training and holdout data samples in comparing the classification accuracy of two or more methods, 10-fold cross-validation is applied to compare the general performance of KCF with three Bayesian network classifiers (i.e., NB, TAN and KDB) and five non-Bayesian network classifiers, i.e., IBK(<italic>k</italic>-Nearest Neighbours) [<xref rid="pone.0182070.ref022" ref-type="bibr">22</xref>], SMO(Support Vector Machine) [<xref rid="pone.0182070.ref023" ref-type="bibr">23</xref>], MultilayerPerception(Artificial Neural Network) [<xref rid="pone.0182070.ref024" ref-type="bibr">24</xref>], DecisionStump(Decision Tree) [<xref rid="pone.0182070.ref025" ref-type="bibr">25</xref>] and SimpleLogistic(linear logistic regression) [<xref rid="pone.0182070.ref026" ref-type="bibr">26</xref>]. In 10-fold cross-validation, whole data are randomly divided to 10 mutually exclusive and approximately equal size subsets. The classification algorithm trained and tested 10 times. In each case, one of the folds is taken as test data and the remaining folds are added to form training data. Thus 10 different test results exist for each training-test configuration. The average of these results gives the test accuracy of the algorithm. All the experiments have been carried out in a C++ software specially designed to deal with out-of-core classification methods. The average classification accuracy (inversely related to zero-one loss [<xref rid="pone.0182070.ref027" ref-type="bibr">27</xref>]) are 75.17%(NB), 80.65%(TAN), 80.43%(KDB), 81.89%(KCF), 78.15%(IBK), 79.67%(SMO), 77.34%(MultilayerPerception), 73.81%(DecisionStump) and 79.53%(SimpleLogistic). Obviously, the proposed KCF algorithm achieves the highest classification accuracy compared with other algorithms and thus performs much more effectively in thyroid disease diagnosis.</p><table-wrap id="pone.0182070.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.t001</object-id><label>Table 1</label><caption><title>Attributes available for analysis.</title></caption><alternatives><graphic id="pone.0182070.t001g" xlink:href="pone.0182070.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Attribute</th><th align="center" rowspan="1" colspan="1">Type</th><th align="center" rowspan="1" colspan="1">Explanation</th><th align="center" rowspan="1" colspan="1">Corresponding symbol in Figs <xref ref-type="fig" rid="pone.0182070.g002">2</xref>&#x02013;<xref ref-type="fig" rid="pone.0182070.g008">8</xref></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">age</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Years</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>0</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">sex</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Female/male</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>1</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">on thyroxine</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>2</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">query on thyroxine</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>3</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">on antithyroid medication</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>4</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">sick</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>5</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">pregnant</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>6</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">thyroid surgery</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>7</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">I131 treatment</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>8</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">query hypothyroid</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>9</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">query hyperthyroid</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>10</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">lithium</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>11</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">goitre</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>12</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">tumor</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>13</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">hypopituitary</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>14</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">psych</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>15</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TSH measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>16</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TSH</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Thyroid stimulating hormone</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>17</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">T3 measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>18</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">T3</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Triiodothyronine</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>19</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TT4 measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>20</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TT4</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Total serum thyroxine</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>21</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">T4U measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>22</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">T4U</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">thyroxine</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>23</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">FTI measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>24</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">FTI</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Free Tyroxine Index</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>25</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TBG measured</td><td align="center" rowspan="1" colspan="1">Binary</td><td align="center" rowspan="1" colspan="1">Yes/no</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>26</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">TBG</td><td align="center" rowspan="1" colspan="1">Numeric</td><td align="center" rowspan="1" colspan="1">Thyroid binding globulin</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>27</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">referral source</td><td align="center" rowspan="1" colspan="1">Categorical</td><td align="center" rowspan="1" colspan="1">WEST, STMW, SVHC, SVI, SVHD, other</td><td align="center" rowspan="1" colspan="1"><italic>X</italic><sub>28</sub></td></tr><tr><td align="left" rowspan="1" colspan="1">Category</td><td align="center" rowspan="1" colspan="1">Categorical</td><td align="center" rowspan="1" colspan="1">20 class labels are divided into 7 groups: Hyperthyroid conditions, Hypothyroid conditions, Binding protein, General health, Replacement therapy, Antithyroid treatment, Miscellaneous</td><td align="center" rowspan="1" colspan="1"><italic>C</italic></td></tr></tbody></table></alternatives></table-wrap><p>To explain the main reason of performance difference of BNCs, we will clarify from the viewpoint of Markov blanket. Compared with low-dependence BNC, high-dependence BNC can demonstrate more conditional dependencies. Thus in the following discussion, we just compare KCF with KDB, both of which are 2-dependence BNCs. KCF will generate a series of submodels, each of which corresponds to different focus for analysis. For example, if <italic>X</italic><sub><italic>i</italic></sub> is the key factor for diagnosis, then doctors can use the <italic>i</italic>th submodel for further analysis. From the definition of Markov blanket, we can get the following conclusion that <italic>X</italic><sub><italic>i</italic></sub> is directly and mutually dependent on attributes {<italic>Pa</italic>(<italic>X</italic><sub><italic>i</italic></sub>), <italic>Ch</italic>(<italic>X</italic><sub><italic>i</italic></sub>)} while indirectly dependent on attributes <italic>PC</italic>(<italic>X</italic><sub><italic>i</italic></sub>). The other attributes are useless for further consideration. The time cost for unnecessary analysis and expenditure on unnecessary physical examination will be decreased greatly. With limited time and space complexity, more Markov blanket attributes means more possible dependency relationships to be mined. The list and number of Markov blanket attributes of each attribute for KCF and KDB are shown in <xref ref-type="fig" rid="pone.0182070.g005">Fig 5</xref> and <xref ref-type="fig" rid="pone.0182070.g006">Fig 6</xref>, respectively. From <xref ref-type="fig" rid="pone.0182070.g006">Fig 6</xref>, for 25 of all of the 29 attributes the number of corresponding Markov blanket attributes for KCF is greater than that for KDB. On average each predictive attribute has 9.1 Markov blanket attributes for KCF, whereas only 4.1 Markov blanket attributes for KDB.</p><fig id="pone.0182070.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g005</object-id><label>Fig 5</label><caption><title>The Markov blanket for KDB (<italic>k</italic> = 2) model is in yellow background and that for KCF (<italic>k</italic> = 2) model is in blue background.</title></caption><graphic xlink:href="pone.0182070.g005"/></fig><fig id="pone.0182070.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g006</object-id><label>Fig 6</label><caption><title>The number of attributes contained in the Markov blanket of each attribute in the KDB (<italic>k</italic> = 2) model and KCF (<italic>k</italic> = 2) model.</title></caption><graphic xlink:href="pone.0182070.g006"/></fig><p>Conditional mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>j</italic></sub>|<italic>C</italic>) can be used to quantitatively evaluate the conditional dependence between <italic>X</italic><sub><italic>i</italic></sub> and <italic>X</italic><sub><italic>j</italic></sub> given <italic>C</italic>. For any given target attribute <italic>X</italic><sub><italic>k</italic></sub>, <italic>X</italic><sub><italic>k</italic></sub> is directly dependent on <italic>Pa</italic>(<italic>X</italic><sub><italic>k</italic></sub>) and <italic>Ch</italic>(<italic>X</italic><sub><italic>k</italic></sub>) is directly dependent on <italic>X</italic><sub><italic>k</italic></sub>. Thus the conditional dependencies are measured by <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>X</italic><sub><italic>k</italic></sub>|<italic>C</italic>) and <italic>I</italic>(<italic>X</italic><sub><italic>j</italic></sub>; <italic>X</italic><sub><italic>k</italic></sub>|<italic>C</italic>) (<italic>X</italic><sub><italic>i</italic></sub> &#x02208; <italic>Pa</italic>(<italic>X</italic><sub><italic>k</italic></sub>), <italic>X</italic><sub><italic>j</italic></sub> &#x02208; <italic>Ch</italic>(<italic>X</italic><sub><italic>k</italic></sub>)), respectively. <italic>PC</italic>(<italic>X</italic><sub><italic>k</italic></sub>) is conditionally dependent on <italic>X</italic><sub><italic>k</italic></sub> but directly dependent on <italic>Ch</italic>(<italic>X</italic><sub><italic>k</italic></sub>). The conditional dependence is measured by <inline-formula id="pone.0182070.e013"><alternatives><graphic xlink:href="pone.0182070.e013.jpg" id="pone.0182070.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>;</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>
<inline-formula id="pone.0182070.e014"><alternatives><graphic xlink:href="pone.0182070.e014.jpg" id="pone.0182070.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. All the conditional dependencies among attributes in <italic>MB</italic>(<italic>X</italic><sub><italic>k</italic></sub>) can then be measured by <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>k</italic></sub>), which is defined by <xref ref-type="disp-formula" rid="pone.0182070.e015">Eq (5)</xref>,
<disp-formula id="pone.0182070.e015"><alternatives><graphic xlink:href="pone.0182070.e015.jpg" id="pone.0182070.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>_</mml:mo><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>P</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mi>P</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>;</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>j</mml:mi><mml:msup><mml:mrow/><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msubsup><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula></p><p>We also compare the average weight of conditional dependencies implicated in <italic>MB</italic>(<italic>X</italic><sub><italic>k</italic></sub>), which is defined by <xref ref-type="disp-formula" rid="pone.0182070.e016">Eq (6)</xref>,
<disp-formula id="pone.0182070.e016"><alternatives><graphic xlink:href="pone.0182070.e016.jpg" id="pone.0182070.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mo>_</mml:mo><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>_</mml:mo><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>_</mml:mo><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mspace width="4pt"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="4pt"/><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>b</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="4pt"/><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula></p><p>The comparison results of <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>k</italic></sub>) between KCF and KDB are shown in <xref ref-type="fig" rid="pone.0182070.g007">Fig 7</xref>. For the first 14 attributes, <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>k</italic></sub>)&#x02248;0 {0 &#x02264; <italic>k</italic> &#x02264; 13} for both KDB and KCF. Thus <italic>X</italic><sub><italic>k</italic></sub> {0 &#x02264; <italic>k</italic> &#x02264; 13} is directly dependent on class variable whereas independent of any other attributes. For 13 of the other 15 attributes, the value of <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>k</italic></sub>) {14 &#x02264; <italic>k</italic> &#x02264; 28} for KCF is greater than that for KDB. The experimental results prove that KCF can fully demonstrate dependency relationships and thus help to increase the classification accuracy.</p><fig id="pone.0182070.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g007</object-id><label>Fig 7</label><caption><p>The sum of conditional mutual information between each attribute and the attributes contained in its Markov blanket is shown in (a). The average of conditional mutual information between each attribute and the attributes contained in its Markov blanket is shown in (b).</p></caption><graphic xlink:href="pone.0182070.g007"/></fig></sec><sec sec-type="conclusions" id="sec007"><title>Discussion</title><p>Thyroid cancer incidence has been rising since 1978, and its prevalence has increased dramatically over the past decade; currently, thyroid cancer is the fifth most common cancer diagnosed among women. By contrast, the incidence of other malignancies, including lung, colorectal, and breast cancer, decreases [<xref rid="pone.0182070.ref028" ref-type="bibr">28</xref>]. A statistical survey in 2014 showed that 10 million Chinese patients have hyperthyroidism, 90 million have hypothyroidism, more than 100 million are afflicted with thyroid nodules or thyroid cancer, and conservatively; more than 200 million are estimated to have thyroid disease. As the second major disease of the endocrine system, the awareness rate and treatment rate of thyroid diseases are very low in China.</p><p>Thyroid nodule is a common clinical problem, and the prevalence of differentiated thyroid cancer increases [<xref rid="pone.0182070.ref029" ref-type="bibr">29</xref>]. Early detection, diagnosis, and treatment are important in curbing the development of thyroid diseases and reducing the mortality rate. Predicting the outcome of diseases and dependency among clinical variables or attributes plays pivotal roles in medical diagnosis and treatment.</p><p>For the detailed analysis, this paper calculates and compares the mutual information <italic>I</italic>(<italic>X</italic><sub><italic>i</italic></sub>; <italic>C</italic>) first. The results are sorted starting from the highest. The attribute order is <italic>X</italic><sub>17</sub>, <italic>X</italic><sub>25</sub>, <italic>X</italic><sub>21</sub>, <italic>X</italic><sub>19</sub>, <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>2</sub>, <italic>X</italic><sub>28</sub>, <italic>X</italic><sub>27</sub>, <italic>X</italic><sub>16</sub>, <italic>X</italic><sub>20</sub>, <italic>X</italic><sub>26</sub>, <italic>X</italic><sub>18</sub>, <italic>X</italic><sub>22</sub>, <italic>X</italic><sub>24</sub>, <italic>X</italic><sub>0</sub>, <italic>X</italic><sub>1</sub>, <italic>X</italic><sub>6</sub>, <italic>X</italic><sub>10</sub>, <italic>X</italic><sub>13</sub>, <italic>X</italic><sub>7</sub>, <italic>X</italic><sub>9</sub>, <italic>X</italic><sub>15</sub>, <italic>X</italic><sub>4</sub>, <italic>X</italic><sub>8</sub>, <italic>X</italic><sub>5</sub>, <italic>X</italic><sub>3</sub>, <italic>X</italic><sub>12</sub>, <italic>X</italic><sub>11</sub>, <italic>X</italic><sub>14</sub>. From the perspective of medical diagnosis, the attribute with the most intimate relationship with the outcome can be considered as the key attribute and should be the focus of the analysis. The attribute <italic>X</italic><sub>17</sub> represents the clinical index for thyroid stimulating hormone (TSH) and should be analyzed initially. TSH can promote the growth of thyroid secreted by adenohypophysis. In addition, TSH can completely improve the function of the thyroid, promoting early release of thyroid hormones and synthesis of T4 and T3.</p><p>To clarify the role of the TSH attribute, this paper displays the structure of the KDB and a KCF submodel in <xref ref-type="fig" rid="pone.0182070.g008">Fig 8(a) and 8(b)</xref>, respectively. To make typical and fair comparison, we set <italic>X</italic><sub>17</sub> as the common root node of both models. As shown in <xref ref-type="fig" rid="pone.0182070.g008">Fig 8(a)</xref>, <italic>X</italic><sub>17</sub> is the common parent of <italic>X</italic><sub>25</sub>, <italic>X</italic><sub>21</sub>, <italic>X</italic><sub>28</sub>, <italic>X</italic><sub>16</sub>, <italic>X</italic><sub>18</sub>, <italic>X</italic><sub>17</sub>, <italic>X</italic><sub>3</sub>, and <italic>X</italic><sub>12</sub>; <italic>X</italic><sub>0</sub> and <italic>X</italic><sub>19</sub> are the parent nodes of the children of <italic>X</italic><sub>17</sub>. <italic>X</italic><sub>0</sub> is the parent node of <italic>X</italic><sub>12</sub>, and <italic>X</italic><sub>19</sub> is the common parent of <italic>X</italic><sub>18</sub> and <italic>X</italic><sub>28</sub>. <italic>MB</italic>(<italic>X</italic><sub>17</sub>) contains 10 attributes. <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub>17</sub>) is 0.902 and <italic>Avg</italic>_<italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub>17</sub>) = 0.09. In the corresponding KCF model shown in <xref ref-type="fig" rid="pone.0182070.g008">Fig 8(b)</xref>, <italic>X</italic><sub>17</sub> is the common parent of <italic>X</italic><sub>23</sub>, <italic>X</italic><sub>24</sub>, <italic>X</italic><sub>25</sub>, <italic>X</italic><sub>27</sub>, and <italic>X</italic><sub>28</sub>, whereas <italic>X</italic><sub>17</sub> has no parent nodes and no parent of children nodes. Thus, <italic>MB</italic>(<italic>X</italic><sub>17</sub>) only contains 5 attributes. <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub>17</sub>) and <italic>Avg</italic>_<italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub>17</sub>) turn to be 0.597 and 0.12, respectively. Similarly, the sum of <italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>i</italic></sub>), i.e., <inline-formula id="pone.0182070.e017"><alternatives><graphic xlink:href="pone.0182070.e017.jpg" id="pone.0182070.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>28</mml:mn></mml:msubsup><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>_</mml:mo><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, is 14.458 for KCF, whereas it is only 6.964 for KDB. The sum of <italic>Avg</italic>_<italic>MB</italic>_<italic>Info</italic>(<italic>X</italic><sub><italic>i</italic></sub>), i.e., <inline-formula id="pone.0182070.e018"><alternatives><graphic xlink:href="pone.0182070.e018.jpg" id="pone.0182070.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>28</mml:mn></mml:msubsup><mml:mi>A</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mo>_</mml:mo><mml:mi>M</mml:mi><mml:mi>B</mml:mi><mml:mo>_</mml:mo><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, is 1.576 for KDB and 1.946 for KCF. Hence, the proposed KCF model describes significant relationships among attributes.</p><fig id="pone.0182070.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.g008</object-id><label>Fig 8</label><caption><title>KDB (<italic>k</italic> = 2) model and a submodel of the KCF (<italic>k</italic> = 2) on thyroid disease date set shown respectively in (a) and (b).</title><p>Attributes {<italic>X</italic><sub>0</sub>, <italic>X</italic><sub>1</sub>, &#x022ef;, <italic>X</italic><sub>28</sub>, <italic>C</italic>} correspond to clinical variables <italic>age</italic>, <italic>sex</italic>, <italic>on thyroxine</italic>, <italic>query on thyroxine</italic>, <italic>on antithyroid medication</italic>, <italic>sick</italic>, <italic>pregnant</italic>, <italic>thyroid surgery</italic>, <italic>I131 treatment</italic>, <italic>query hypothyroid</italic>, <italic>query hyperthyroid</italic>, <italic>lithium</italic>, <italic>goitre</italic>, <italic>tumor</italic>, <italic>hypopituitary</italic>, <italic>psych</italic>, <italic>TSH measured</italic>, <italic>TSH</italic>, <italic>T3 measured</italic>, <italic>T3</italic>, <italic>TT4 measured</italic>, <italic>TT4</italic>, <italic>T4U measured</italic>, <italic>T4U</italic>, <italic>FTI measured</italic>, <italic>FTI</italic>, <italic>TBG measured</italic>, <italic>TBG</italic>, <italic>referral source</italic> and <italic>Class</italic> respectively.</p></caption><graphic xlink:href="pone.0182070.g008"/></fig><p>MST contains the most significant dependency relationships, whereas the KDB model can only contain portions of the MST. Additionally, the KCF algorithm can generate a series of submodels rather than one model alone. Thus, for medical diagnosis, any clinical variable or attribute related to thyroid diseases can be regarded as the original cause, and an in-depth research can be conducted on the disease. Hence, the proposed KCF model can handle various patient conditions and is more suitable for providing appropriate treatment compared with a model with a rigid root node generated by other algorithms.</p><p>Sensitivity and specificity are statistical measures of the performance of a binary classification test, also known in statistics as classification function. In the context of medical tests sensitivity is the extent to which true positives are not missed/overlooked and specificity is the extent to which positives really represent the condition of interest and not some other condition being mistaken for it. So we select 12 datasets with binary class labels from UCI for comparison of classification accuracy. <xref ref-type="table" rid="pone.0182070.t002">Table 2</xref> summarizes the characteristics of each dataset, including the numbers of instances, attributes and classes. Averaged One-dependence Estimators (AODE) [<xref rid="pone.0182070.ref030" ref-type="bibr">30</xref>], which utilizes a restricted class of one-dependence estimators and aggregates the predictions of all qualified estimators within this class, is introduced to compare the bagging performance of KCF.</p><table-wrap id="pone.0182070.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.t002</object-id><label>Table 2</label><caption><title>Datasets.</title></caption><alternatives><graphic id="pone.0182070.t002g" xlink:href="pone.0182070.t002"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">No.</th><th align="left" rowspan="1" colspan="1">dataset</th><th align="center" rowspan="1" colspan="1">Instance</th><th align="center" rowspan="1" colspan="1">Attribute</th><th align="center" rowspan="1" colspan="1">Class</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">Echocardiogram</td><td align="center" rowspan="1" colspan="1">131</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">Heart*</td><td align="center" rowspan="1" colspan="1">270</td><td align="center" rowspan="1" colspan="1">13</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">Heart Disease*</td><td align="center" rowspan="1" colspan="1">303</td><td align="center" rowspan="1" colspan="1">13</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">Chess</td><td align="center" rowspan="1" colspan="1">551</td><td align="center" rowspan="1" colspan="1">39</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">Breast-cancer-w*</td><td align="center" rowspan="1" colspan="1">699</td><td align="center" rowspan="1" colspan="1">9</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">Pima-ind-diabetes*</td><td align="center" rowspan="1" colspan="1">768</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">Tic-tac-toe</td><td align="center" rowspan="1" colspan="1">958</td><td align="center" rowspan="1" colspan="1">9</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">German</td><td align="center" rowspan="1" colspan="1">1000</td><td align="center" rowspan="1" colspan="1">20</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">9</td><td align="left" rowspan="1" colspan="1">Spambase</td><td align="center" rowspan="1" colspan="1">4601</td><td align="center" rowspan="1" colspan="1">57</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">Mushroom</td><td align="center" rowspan="1" colspan="1">8124</td><td align="center" rowspan="1" colspan="1">22</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">11</td><td align="left" rowspan="1" colspan="1">Adult</td><td align="center" rowspan="1" colspan="1">48842</td><td align="center" rowspan="1" colspan="1">14</td><td align="center" rowspan="1" colspan="1">2</td></tr><tr><td align="left" rowspan="1" colspan="1">12</td><td align="left" rowspan="1" colspan="1">Census-income</td><td align="center" rowspan="1" colspan="1">299285</td><td align="center" rowspan="1" colspan="1">41</td><td align="center" rowspan="1" colspan="1">2</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p>the datasets denoted with symbol &#x0201c;*&#x0201d; will be used for comparing sensitivity and specificity.</p></fn></table-wrap-foot></table-wrap><p>Experimental results of average classification accuracy for different BNCs are shown in <xref ref-type="table" rid="pone.0182070.t003">Table 3</xref>. Friedman test [<xref rid="pone.0182070.ref031" ref-type="bibr">31</xref>], which is a non-parametric measure to compare the ranks of the algorithms for each dataset separately. The ranks of algorithms for each dataset are calculated separately (average ranks are assigned if tied values exist). The null-hypothesis is that all the algorithms performs almost equivalently and there is no significant difference in terms of ranks. The Friedman statistic can be computed as <xref ref-type="disp-formula" rid="pone.0182070.e019">Eq (7)</xref> shows,
<disp-formula id="pone.0182070.e019"><alternatives><graphic xlink:href="pone.0182070.e019.jpg" id="pone.0182070.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>12</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:msubsup><mml:mi>R</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>-</mml:mo><mml:mn>3</mml:mn><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
where <inline-formula id="pone.0182070.e020"><alternatives><graphic xlink:href="pone.0182070.e020.jpg" id="pone.0182070.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0182070.e021"><alternatives><graphic xlink:href="pone.0182070.e021.jpg" id="pone.0182070.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:msubsup><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is the rank of the <italic>j</italic>-th of <italic>t</italic> algorithms on the <italic>i</italic>-th of <italic>N</italic> datasets. Thus, for any pre-determined level of significance <italic>&#x003b1;</italic> the null hypothesis will be rejected if <inline-formula id="pone.0182070.e022"><alternatives><graphic xlink:href="pone.0182070.e022.jpg" id="pone.0182070.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>&#x0003e;</mml:mo><mml:msubsup><mml:mi>&#x003c7;</mml:mi><mml:mi>&#x003b1;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, which is the upper-tail critical value having <italic>t</italic> &#x02212; 1 degrees of freedom. The critical value of <inline-formula id="pone.0182070.e023"><alternatives><graphic xlink:href="pone.0182070.e023.jpg" id="pone.0182070.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:msubsup><mml:mi>&#x003c7;</mml:mi><mml:mi>&#x003b1;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> for <italic>&#x003b1;</italic> = 0.02 is 11.668. With 5 algorithms and 12 datasets, the friedman statistic <italic>F</italic><sub><italic>r</italic></sub> = 18.55 and <italic>P</italic> &#x0003c; 0.001. Hence the null-hypotheses is rejected again. The average ranks of different classifiers are {NB(1.54), TAN(3.00), AODE(2.54), KDB(3.88), KCF(4.04)}. Thus KCF with the highest rank is the most effective BNC from the perspectives of classification accuracy.</p><table-wrap id="pone.0182070.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.t003</object-id><label>Table 3</label><caption><title>Experimental results of average classification accuracy for datasets with binary class labels.</title></caption><alternatives><graphic id="pone.0182070.t003g" xlink:href="pone.0182070.t003"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Dataset</th><th align="center" rowspan="1" colspan="1">NB</th><th align="center" rowspan="1" colspan="1">TAN</th><th align="center" rowspan="1" colspan="1">KCF</th><th align="center" rowspan="1" colspan="1">KDB</th><th align="center" rowspan="1" colspan="1">AODE</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Adult</td><td align="char" char="." rowspan="1" colspan="1">84.2%</td><td align="char" char="." rowspan="1" colspan="1">86.2%</td><td align="char" char="." rowspan="1" colspan="1">85.1%</td><td align="char" char="." rowspan="1" colspan="1">86.2%</td><td align="char" char="." rowspan="1" colspan="1">86.8%</td></tr><tr><td align="left" rowspan="1" colspan="1">Breast-cancer-w</td><td align="char" char="." rowspan="1" colspan="1">95.8%</td><td align="char" char="." rowspan="1" colspan="1">96.4%</td><td align="char" char="." rowspan="1" colspan="1">97.4%</td><td align="char" char="." rowspan="1" colspan="1">95.3%</td><td align="char" char="." rowspan="1" colspan="1">94.6%</td></tr><tr><td align="left" rowspan="1" colspan="1">Census-income</td><td align="char" char="." rowspan="1" colspan="1">76.3%</td><td align="char" char="." rowspan="1" colspan="1">93.6%</td><td align="char" char="." rowspan="1" colspan="1">89.9%</td><td align="char" char="." rowspan="1" colspan="1">94.9%</td><td align="char" char="." rowspan="1" colspan="1">94.9%</td></tr><tr><td align="left" rowspan="1" colspan="1">Chess</td><td align="char" char="." rowspan="1" colspan="1">88.7%</td><td align="char" char="." rowspan="1" colspan="1">90.7%</td><td align="char" char="." rowspan="1" colspan="1">90.0%</td><td align="char" char="." rowspan="1" colspan="1">90.0%</td><td align="char" char="." rowspan="1" colspan="1">92.4%</td></tr><tr><td align="left" rowspan="1" colspan="1">Echocardiogram</td><td align="char" char="." rowspan="1" colspan="1">66.4%</td><td align="char" char="." rowspan="1" colspan="1">67.2%</td><td align="char" char="." rowspan="1" colspan="1">67.9%</td><td align="char" char="." rowspan="1" colspan="1">65.6%</td><td align="char" char="." rowspan="1" colspan="1">66.4%</td></tr><tr><td align="left" rowspan="1" colspan="1">German</td><td align="char" char="." rowspan="1" colspan="1">74.7%</td><td align="char" char="." rowspan="1" colspan="1">72.7%</td><td align="char" char="." rowspan="1" colspan="1">75.2%</td><td align="char" char="." rowspan="1" colspan="1">71.1%</td><td align="char" char="." rowspan="1" colspan="1">73.0%</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart</td><td align="char" char="." rowspan="1" colspan="1">80.2%</td><td align="char" char="." rowspan="1" colspan="1">80.7%</td><td align="char" char="." rowspan="1" colspan="1">80.8%</td><td align="char" char="." rowspan="1" colspan="1">81.9%</td><td align="char" char="." rowspan="1" colspan="1">80.4%</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart Disease</td><td align="char" char="." rowspan="1" colspan="1">79.9%</td><td align="char" char="." rowspan="1" colspan="1">79.2%</td><td align="char" char="." rowspan="1" colspan="1">78.8%</td><td align="char" char="." rowspan="1" colspan="1">77.6%</td><td align="char" char="." rowspan="1" colspan="1">79.6%</td></tr><tr><td align="left" rowspan="1" colspan="1">Mushrooms</td><td align="char" char="." rowspan="1" colspan="1">98.0%</td><td align="char" char="." rowspan="1" colspan="1">100.0%</td><td align="char" char="." rowspan="1" colspan="1">100.0%</td><td align="char" char="." rowspan="1" colspan="1">100.0%</td><td align="char" char="." rowspan="1" colspan="1">100.0%</td></tr><tr><td align="left" rowspan="1" colspan="1">Pima-ind-diabetes</td><td align="char" char="." rowspan="1" colspan="1">75.5%</td><td align="char" char="." rowspan="1" colspan="1">76.2%</td><td align="char" char="." rowspan="1" colspan="1">76.2%</td><td align="char" char="." rowspan="1" colspan="1">75.5%</td><td align="char" char="." rowspan="1" colspan="1">76.3%</td></tr><tr><td align="left" rowspan="1" colspan="1">Spambase</td><td align="char" char="." rowspan="1" colspan="1">89.8%</td><td align="char" char="." rowspan="1" colspan="1">93.3%</td><td align="char" char="." rowspan="1" colspan="1">93.3%</td><td align="char" char="." rowspan="1" colspan="1">93.6%</td><td align="char" char="." rowspan="1" colspan="1">94.1%</td></tr><tr><td align="left" rowspan="1" colspan="1">Tic-tac-toe</td><td align="char" char="." rowspan="1" colspan="1">69.3%</td><td align="char" char="." rowspan="1" colspan="1">77.1%</td><td align="char" char="." rowspan="1" colspan="1">73.5%</td><td align="char" char="." rowspan="1" colspan="1">79.6%</td><td align="char" char="." rowspan="1" colspan="1">80.6%</td></tr></tbody></table></alternatives></table-wrap><p>When dealing with imbalanced class distribution, traditional classifiers are easily overwhelmed by instances from majority classes while the instances from minority classes are usually ignored. An useful performance measure is the balanced accuracy (BAC) [<xref rid="pone.0182070.ref032" ref-type="bibr">32</xref>] which avoids inflated performance estimates and defined as <xref ref-type="disp-formula" rid="pone.0182070.e024">Eq (8)</xref> shows. It is defined as the arithmetic mean of sensitivity and specificity, which are calculated by knowing the <italic>m</italic> binary outputs of the classifiers (indicating membership to given classes). Overall performance is calculated by conducting a leave-one-out test for all training samples.
<disp-formula id="pone.0182070.e024"><alternatives><graphic xlink:href="pone.0182070.e024.jpg" id="pone.0182070.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula>
The experimental results of sensitivity, specificity and BAC for BNCs are shown in <xref ref-type="table" rid="pone.0182070.t004">Table 4</xref>. By comparing via two-tailed binomial sign test with a 95% confidence level, <xref ref-type="table" rid="pone.0182070.t005">Table 5</xref> shows corresponding win/draw/loss (W/D/L) records summarizing the relative BAC of the different BNCs. The W/D/L record in cell [<italic>i</italic>, <italic>j</italic>] of each table contains the number of datasets in which BNC on row <italic>i</italic> has lower, equal or higher outcome relative to the BNC on column <italic>j</italic>. We could see from <xref ref-type="table" rid="pone.0182070.t005">Table 5</xref> that the bagging mechanism helps AODE increase BAC significantly often relative to TAN and NB. KDB can achieve not only higher classification accuracy but also higher BAC than TAN. KCF utilizes the bagging mechanism of AODE and can represent high-dependence relationships. This may be the main reason why KCF achieves higher BAC more often than the other four BNCs.</p><table-wrap id="pone.0182070.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.t004</object-id><label>Table 4</label><caption><title>Experimental results of sensitivity, specificity and BAC for medical datasets with binary class labels.</title></caption><alternatives><graphic id="pone.0182070.t004g" xlink:href="pone.0182070.t004"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Dataset</th><th align="center" rowspan="1" colspan="1">NB</th><th align="center" rowspan="1" colspan="1">TAN</th><th align="center" rowspan="1" colspan="1">AODE</th><th align="center" rowspan="1" colspan="1">KDB</th><th align="center" rowspan="1" colspan="1">KCF</th></tr></thead><tbody><tr><td align="left" rowspan="4" colspan="1">sensitivity</td><td align="left" rowspan="1" colspan="1">Breast-cancer-w</td><td align="char" char="." rowspan="1" colspan="1">0.969</td><td align="char" char="." rowspan="1" colspan="1">0.973</td><td align="char" char="." rowspan="1" colspan="1">0.965</td><td align="char" char="." rowspan="1" colspan="1">0.958</td><td align="char" char="." rowspan="1" colspan="1">0.971</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart</td><td align="char" char="." rowspan="1" colspan="1">0.840</td><td align="char" char="." rowspan="1" colspan="1">0.853</td><td align="char" char="." rowspan="1" colspan="1">0.860</td><td align="char" char="." rowspan="1" colspan="1">0.853</td><td align="char" char="." rowspan="1" colspan="1">0.806</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart-disease-c</td><td align="char" char="." rowspan="1" colspan="1">0.829</td><td align="char" char="." rowspan="1" colspan="1">0.856</td><td align="char" char="." rowspan="1" colspan="1">0.842</td><td align="char" char="." rowspan="1" colspan="1">0.816</td><td align="char" char="." rowspan="1" colspan="1">0.786</td></tr><tr><td align="left" rowspan="1" colspan="1">Pima-ind-diabetes</td><td align="char" char="." rowspan="1" colspan="1">0.820</td><td align="char" char="." rowspan="1" colspan="1">0.842</td><td align="char" char="." rowspan="1" colspan="1">0.824</td><td align="char" char="." rowspan="1" colspan="1">0.838</td><td align="char" char="." rowspan="1" colspan="1">0.816</td></tr><tr><td align="left" rowspan="4" colspan="1">specificity</td><td align="left" rowspan="1" colspan="1">Breast-cancer-w</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.917</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.929</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.945</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.975</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.975</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.742</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.750</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.756</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.792</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.854</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart-disease-c</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.748</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.741</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.813</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.776</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.846</td></tr><tr><td align="left" rowspan="1" colspan="1">Pima-ind-diabetes</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.634</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.612</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.631</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.619</td><td align="char" char="." style="background-color: #EBEDEF" rowspan="1" colspan="1">0.642</td></tr><tr><td align="left" rowspan="4" colspan="1">BAC</td><td align="left" rowspan="1" colspan="1">Breast-cancer-w</td><td align="char" char="." rowspan="1" colspan="1">0.943</td><td align="char" char="." rowspan="1" colspan="1">0.952</td><td align="char" char="." rowspan="1" colspan="1">0.955</td><td align="char" char="." rowspan="1" colspan="1">0.966</td><td align="char" char="." rowspan="1" colspan="1">0.973</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart</td><td align="char" char="." rowspan="1" colspan="1">0.798</td><td align="char" char="." rowspan="1" colspan="1">0.802</td><td align="char" char="." rowspan="1" colspan="1">0.808</td><td align="char" char="." rowspan="1" colspan="1">0.826</td><td align="char" char="." rowspan="1" colspan="1">0.830</td></tr><tr><td align="left" rowspan="1" colspan="1">Heart-disease-c</td><td align="char" char="." rowspan="1" colspan="1">0.788</td><td align="char" char="." rowspan="1" colspan="1">0.798</td><td align="char" char="." rowspan="1" colspan="1">0.802</td><td align="char" char="." rowspan="1" colspan="1">0.797</td><td align="char" char="." rowspan="1" colspan="1">0.816</td></tr><tr><td align="left" rowspan="1" colspan="1">Pima-ind-diabetes</td><td align="char" char="." rowspan="1" colspan="1">0.727</td><td align="char" char="." rowspan="1" colspan="1">0.726</td><td align="char" char="." rowspan="1" colspan="1">0.727</td><td align="char" char="." rowspan="1" colspan="1">0.728</td><td align="char" char="." rowspan="1" colspan="1">0.729</td></tr></tbody></table></alternatives></table-wrap><table-wrap id="pone.0182070.t005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0182070.t005</object-id><label>Table 5</label><caption><title>Win-draw-loss records for different BNCs in terms of BAC.</title></caption><alternatives><graphic id="pone.0182070.t005g" xlink:href="pone.0182070.t005"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Dataset</th><th align="left" rowspan="1" colspan="1">NB</th><th align="left" rowspan="1" colspan="1">TAN</th><th align="left" rowspan="1" colspan="1">AODE</th><th align="left" rowspan="1" colspan="1">KDB</th></tr></thead><tbody><tr><td align="left" rowspan="4" colspan="1">BAC</td><td align="left" rowspan="1" colspan="1">TAN</td><td align="left" rowspan="1" colspan="1">1/3/0</td><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">AODE</td><td align="left" rowspan="1" colspan="1">2/2/0</td><td align="left" rowspan="1" colspan="1">1/3/0</td><td align="left" rowspan="1" colspan="1">-</td><td align="left" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">KDB</td><td align="left" rowspan="1" colspan="1">2/2/0</td><td align="left" rowspan="1" colspan="1">2/2/0</td><td align="left" rowspan="1" colspan="1">2/1/1</td><td align="left" rowspan="1" colspan="1">-</td></tr><tr><td align="left" rowspan="1" colspan="1">KCF</td><td align="left" rowspan="1" colspan="1">3/1/0</td><td align="left" rowspan="1" colspan="1">3/1/0</td><td align="left" rowspan="1" colspan="1">3/1/0</td><td align="left" rowspan="1" colspan="1">2/2/0</td></tr></tbody></table></alternatives></table-wrap></sec><sec sec-type="conclusions" id="sec008"><title>Conclusion</title><p>Bayesian network can graphically describe the conditional dependencies implicit in training data and Bayesian network classifiers have been previously demonstrated to perform efficiently in medical diagnosis and treatment. One single data mining model cannot deal with all difficult and complicated cases. KCF, which uses the same learning strategy as that of KDB, simultaneously provides <italic>n</italic> submodels rather than one. This improvement helps KCF to describe more significant conditional dependencies. The experimental study on UCI datasets shows that KCF enjoys obvious advantage in classification over other BNCs.</p></sec></body><back><ack><p>This work was supported by the National Science Foundation of China (Grant No. 61272209) and the Agreement of Science &#x00026; Technology Development Project, Jilin Province (No. 20150101014JC).</p></ack><ref-list><title>References</title><ref id="pone.0182070.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Yoo</surname><given-names>I</given-names></name>, <name><surname>Alafaireet</surname><given-names>P</given-names></name>, <name><surname>Marinov</surname><given-names>M</given-names></name>. <article-title>Data mining in healthcare and biomedicine: a survey of the literature</article-title>. <source>Journal of Medical Systems</source>. <year>2012</year>; <volume>36</volume>(<issue>4</issue>): <fpage>2431</fpage>&#x02013;<lpage>2448</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10916-011-9710-5">10.1007/s10916-011-9710-5</ext-link></comment>
<pub-id pub-id-type="pmid">21537851</pub-id></mixed-citation></ref><ref id="pone.0182070.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Wu</surname><given-names>X</given-names></name>, <name><surname>Zhu</surname><given-names>X</given-names></name>, <name><surname>Wu</surname><given-names>GQ</given-names></name>. <article-title>Data Mining with Big Data</article-title>. <source>IEEE Transactions on Knowledge &#x00026; Data Engineering</source>. <year>2014</year>; <volume>26</volume>(<issue>1</issue>): <fpage>97</fpage>&#x02013;<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TKDE.2013.109">10.1109/TKDE.2013.109</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Sumalatha</surname><given-names>G</given-names></name>, <name><surname>Muniraj</surname><given-names>NJR</given-names></name>. <article-title>Survey on medical diagnosis using data mining techniques</article-title>. <source>International Conference on Optical Imaging Sensor and Security</source>. <year>2013</year>; <fpage>1</fpage>&#x02013;<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/ICOISS.2013.6678433">10.1109/ICOISS.2013.6678433</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref004"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Liu</surname><given-names>DY</given-names></name>, <name><surname>Chen</surname><given-names>HL</given-names></name>, <name><surname>Yang</surname><given-names>B</given-names></name>, <name><surname>Lv</surname><given-names>XE</given-names></name>, <name><surname>Li</surname><given-names>LN</given-names></name>. <article-title>Design of an Enhanced Fuzzy <italic>k</italic>-nearest Neighbor Classifier Based Computer Aided Diagnostic System for Thyroid Disease</article-title>. <source>Journal of Medical Systems</source>, <year>2012</year>; <volume>36</volume>(<issue>5</issue>), <fpage>3243</fpage>&#x02013;<lpage>3254</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10916-011-9815-x">10.1007/s10916-011-9815-x</ext-link></comment>
<pub-id pub-id-type="pmid">22198094</pub-id></mixed-citation></ref><ref id="pone.0182070.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Xu</surname><given-names>YB</given-names></name>, <name><surname>Wang</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>Q</given-names></name>, <name><surname>Jiang</surname><given-names>J</given-names></name>, <name><surname>Ma</surname><given-names>WQ</given-names></name>. <article-title>Logistic regression analysis of contrast-enhanced ultrasound and conventional ultrasound characteristics of sub-centimeter thyroid nodules</article-title>. <source>Ultrasound in Medicine and Biology</source>, <year>2015</year>; <volume>41</volume>(<issue>12</issue>): <fpage>3102</fpage>&#x02013;<lpage>3108</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.ultrasmedbio.2015.04.026">10.1016/j.ultrasmedbio.2015.04.026</ext-link></comment><pub-id pub-id-type="pmid">26423183</pub-id></mixed-citation></ref><ref id="pone.0182070.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Feyzullah</surname><given-names>T</given-names></name>. <article-title>A comparative study on thyroid disease diagnosis using neural networks</article-title>. <source>Expert Systems with Applications</source>, <year>2009</year>; <volume>36</volume>(<issue>1</issue>): <fpage>944</fpage>&#x02013;<lpage>949</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.eswa.2007.10.010">10.1016/j.eswa.2007.10.010</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Galli</surname><given-names>M</given-names></name>, <name><surname>Zoppis</surname><given-names>I</given-names></name>, <name><surname>Sio</surname><given-names>GD</given-names></name>, <name><surname>Chinello</surname><given-names>C</given-names></name>, <name><surname>Pagni</surname><given-names>F</given-names></name>. <article-title>A Support Vector Machine Classification of Thyroid Bioptic Specimens Using MALDI-MSI Data</article-title>. <source>Advances in Bioinformatics</source>, <year>2016</year>; <volume>2016</volume>(<issue>1</issue>): <fpage>1</fpage>&#x02013;<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1155/2016/3791214">10.1155/2016/3791214</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Pyo</surname><given-names>JS</given-names></name>, <name><surname>Sohn</surname><given-names>JH</given-names></name>, <name><surname>Kang</surname><given-names>G</given-names></name>. <article-title>Diagnostic assessment of intraoperative cytology for papillary thyroid carcinoma: using a decision tree analysis</article-title>. <source>Journal of Endocrinological Investigation</source>, <year>2016</year>; <fpage>1</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Trotta</surname><given-names>R</given-names></name>. <article-title>Bayes in the sky: Bayesian inference and model selection in cosmology</article-title>. <source>Contemporary Physics</source>. <year>2008</year>; <volume>49</volume>(<issue>2</issue>): <fpage>71</fpage>&#x02013;<lpage>104</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/00107510802066753">10.1080/00107510802066753</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Reiz</surname><given-names>B</given-names></name>, <name><surname>Csat&#x000f3;</surname><given-names>L</given-names></name>. <article-title>Tree-like bayesian network classifiers for surgery survival chance prediction</article-title>. <source>International Journal of Computers Communications &#x00026; Control</source>. <year>2008</year>; <volume>3</volume>(<issue>3</issue>): <fpage>470</fpage>&#x02013;<lpage>474</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref011"><label>11</label><mixed-citation publication-type="other">Arroyo-Figueroa G, Sucar LE. A Temporal Bayesian Network for Diagnosis and Prediction. Eprint Arxiv. 2013; 13&#x02013;20.</mixed-citation></ref><ref id="pone.0182070.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Gadewadikar</surname><given-names>J</given-names></name>, <name><surname>Kuljaca</surname><given-names>O</given-names></name>, <name><surname>Agyepong</surname><given-names>K</given-names></name>. <article-title>Exploring Bayesian networks for automated breast cancer detection</article-title>. <source>IEEE Southeastcon</source>. <year>2009</year>; <fpage>153</fpage>&#x02013;<lpage>157</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref013"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Jun</surname><given-names>CH</given-names></name>. <article-title>Classification of High Dimensionality Data through Feature Selection Using Markov Blanket</article-title>. <source>Industrial Engineering &#x00026; Management Systems</source>. <year>2015</year>; <volume>14</volume>(<issue>2</issue>):<fpage>210</fpage>&#x02013;<lpage>219</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7232/iems.2015.14.2.210">10.7232/iems.2015.14.2.210</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref014"><label>14</label><mixed-citation publication-type="other">Koller D, Sahami M. Toward Optimal Feature Selection. Proc. 13th International Conference on Machine Learning. Morgan Kaufmann, 1996; 284&#x02013;292.</mixed-citation></ref><ref id="pone.0182070.ref015"><label>15</label><mixed-citation publication-type="book">
<name><surname>Fu</surname><given-names>S</given-names></name>, <name><surname>Desmarais</surname><given-names>MC</given-names></name>. <chapter-title>Tradeoff Analysis of Different Markov Blanket Local Learning Approaches</chapter-title>
<source>Pacific-asia Conference on Advances in Knowledge Discovery &#x00026; Data Mining</source>. <publisher-name>Springer-Verlag</publisher-name>
<year>2008</year>; <fpage>562</fpage>&#x02013;<lpage>571</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref016"><label>16</label><mixed-citation publication-type="other">UCI Machine Learning Repository. David Aha. 1987. <comment><ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref017"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Heckerman</surname><given-names>D</given-names></name>. <article-title>A tutorial on learning with bayesian networks</article-title>. <source>Learning in Graphical Models</source>. <year>1995</year>; <volume>25</volume>(<issue>4</issue>):<fpage>33</fpage>&#x02013;<lpage>82</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Friedman</surname><given-names>N</given-names></name>, <name><surname>Dan</surname><given-names>G</given-names></name>, <name><surname>Goldszmidt</surname><given-names>M</given-names></name>. <article-title>Bayesian network classifiers</article-title>. <source>Wiley Encyclopedia of Operations Research &#x00026; Management Science</source>, <year>2011</year>; <volume>29</volume>(<issue>2-3</issue>):<fpage>598</fpage>&#x02013;<lpage>605</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Chow</surname><given-names>CK</given-names></name>, <name><surname>Liu</surname><given-names>CN</given-names></name>. <article-title>Approximating discrete probability distributions with dependence trees</article-title>. <source>IEEE Transactions on Information Theory</source>. <year>1968</year>; <volume>14</volume>(<issue>3</issue>):<fpage>462</fpage>&#x02013;<lpage>467</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TIT.1968.1054142">10.1109/TIT.1968.1054142</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref020"><label>20</label><mixed-citation publication-type="other">Sahami M. Learning Limited Dependence Bayesian Classifiers. In the 2nd International Conference. Knowledge Discovery and Data mining (KKD). 1996; 335&#x02013;338.</mixed-citation></ref><ref id="pone.0182070.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Martinez</surname><given-names>AM</given-names></name>, <name><surname>Webb</surname><given-names>GI</given-names></name>, <name><surname>Chen</surname><given-names>SL</given-names></name>, <name><surname>Nayyar</surname><given-names>AZ</given-names></name>. <article-title>Scalable learning of Bayesian network classifiers</article-title>. <source>Journal of Machine Learning Research</source>. <year>2013</year>; <fpage>1</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref022"><label>22</label><mixed-citation publication-type="journal">
<name><surname>David</surname><given-names>WA</given-names></name>, <name><surname>Dennis</surname><given-names>K</given-names></name>, <name><surname>Marc</surname><given-names>KA</given-names></name>. <article-title>Instance-based learning algorithms</article-title>. <source>Machine Learning</source>, <year>1991</year>; <volume>6</volume>(<issue>1</issue>): <fpage>37</fpage>&#x02013;<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00153759">10.1007/BF00153759</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Keerthi</surname><given-names>SS</given-names></name>, <name><surname>Shevade</surname><given-names>SK</given-names></name>, <name><surname>Bhattacharyya</surname><given-names>C</given-names></name>, <name><surname>Murthy</surname><given-names>KRK</given-names></name>. <article-title>Improvements to Platt&#x02019;s SMO Algorithm for SVM Classifier Design</article-title>. <source>Neural Computation</source>, <year>1989</year>; <volume>13</volume>(<issue>3</issue>): <fpage>637</fpage>&#x02013;<lpage>649</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976601300014493">10.1162/089976601300014493</ext-link></comment></mixed-citation></ref><ref id="pone.0182070.ref024"><label>24</label><mixed-citation publication-type="other">David R, James M. Parallel Distributed Processing: Explorations in the Microstructure of Cognition. American Scientist, 1988.</mixed-citation></ref><ref id="pone.0182070.ref025"><label>25</label><mixed-citation publication-type="other">Iba Wayne, Langley P. Induction of One-Level Decision Trees, in Proceedings of the Ninth International Conference on Machine Learning, San Francisco, CA: Morgan Kaufmann, 1992; 233&#x02013;240.</mixed-citation></ref><ref id="pone.0182070.ref026"><label>26</label><mixed-citation publication-type="other">Marc S, Eibe F, Mark H. Speeding up logistic model tree induction. in Proceeding of the 9th European conference on Principles and Practice of Knowledge Discovery in Databases, 2005; 675&#x02013;683.</mixed-citation></ref><ref id="pone.0182070.ref027"><label>27</label><mixed-citation publication-type="journal">
<name><surname>Burduk</surname><given-names>R</given-names></name>. <article-title>Comparison of cost for zero-one and stage-dependent fuzzy loss function</article-title>. <source>Intelligent Information &#x00026; Database Systems</source>. <year>2012</year>; <volume>7196</volume>:<fpage>385</fpage>&#x02013;<lpage>392</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref028"><label>28</label><mixed-citation publication-type="journal">
<name><surname>O&#x02019;Grady</surname><given-names>TJ</given-names></name>, <name><surname>Gates</surname><given-names>MA</given-names></name>, <name><surname>Boscoe</surname><given-names>FP</given-names></name>. <article-title>Thyroid cancer incidence attributable to overdiagnosis in the United States 1981-2011: Thyroid Cancer Overdiagnosis</article-title>. <source>International Journal of Cancer</source>. <year>2015</year>; <fpage>2664</fpage>&#x02013;<lpage>2673</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/ijc.29634">10.1002/ijc.29634</ext-link></comment>
<pub-id pub-id-type="pmid">26069163</pub-id></mixed-citation></ref><ref id="pone.0182070.ref029"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Cooper</surname><given-names>DS</given-names></name>, <name><surname>Doherty</surname><given-names>GM</given-names></name>, <name><surname>Haugen</surname><given-names>BR</given-names></name>, <name><surname>Kloos</surname><given-names>RT</given-names></name>. <article-title>Revised American Thyroid Association management guidelines for patients with thyroid nodules and differentiated thyroid cancer</article-title>. <source>Thyroid Official Journal of the American Thyroid Association</source>. <year>2009</year>; <volume>19</volume>(<issue>2</issue>): <fpage>1167</fpage>&#x02013;<lpage>1214</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1089/thy.2009.0110">10.1089/thy.2009.0110</ext-link></comment>
<pub-id pub-id-type="pmid">19860577</pub-id></mixed-citation></ref><ref id="pone.0182070.ref030"><label>30</label><mixed-citation publication-type="other">Zheng F, Geoffrey W. Efficient lazy elimination for averaged one-dependence estimators. in Proceedings of the Twenty-third International Conference on Machine Learning, 2006; 1113&#x02013;1120.</mixed-citation></ref><ref id="pone.0182070.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Dem&#x00161;ar</surname><given-names>J</given-names></name>. <article-title>Statistical Comparisons of Classifiers over Multiple Data Sets</article-title>. <source>Journal of Machine Learning Research</source>. <year>2006</year>; <volume>7</volume>: <fpage>1</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="pone.0182070.ref032"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Redlarski</surname><given-names>G</given-names></name>, <name><surname>Gradolewski</surname><given-names>D</given-names></name>, <name><surname>Palkowski</surname><given-names>A</given-names></name>. <article-title>A System for Heart Sounds Classification</article-title>. <source>PLoS ONE</source>. <year>2014</year>; <volume>9</volume>(<issue>11</issue>): <fpage>e112673</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0112673">10.1371/journal.pone.0112673</ext-link></comment>
<pub-id pub-id-type="pmid">25393113</pub-id></mixed-citation></ref></ref-list></back></article>