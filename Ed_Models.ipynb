{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T12:06:43.973737Z",
     "start_time": "2018-02-16T12:06:41.100969Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from collections import defaultdict\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.doc2vec import TaggedDocument,TaggedLineDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "\n",
    "\n",
    "\n",
    "# #from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "# from collections import OrderedDict\n",
    "# import multiprocessing\n",
    "# from IPython.display import Image\n",
    "# import requests\n",
    "# from random import randint \n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.cluster import AffinityPropagation\n",
    "# #import matplotlib.pyplot as plt\n",
    "# #%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"volume2/testDB.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### saving abstract tokens to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PLOS_ALL',), ('PLOS_ALL_tok',), ('ed_concat_abtoks',), ('ed_concat',)]\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f912dcd87a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('drop table if exists ed_concat_abtoks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * from ed_concat', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>editors</th>\n",
       "      <th>ab_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alash'le G. Abimiku</td>\n",
       "      <td>'objectiveto', 'evalu', 'cost', 'effect', 'qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alessandro D'Ausilio</td>\n",
       "      <td>'test', 'whether', 'pre', 'assign', 'arm', 'mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anderson de Souza Sant'Ana</td>\n",
       "      <td>'human', 'migrat', 'impli', 'adapt', 'new', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Avi Ma'ayan</td>\n",
       "      <td>'real', 'time', 'quantit', 'pcr', 'qpcr', 'sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bonnie O'Connor</td>\n",
       "      <td>'half', 'gener', 'popul', 'attend', 'screen', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                     editors  \\\n",
       "0      0         Alash'le G. Abimiku   \n",
       "1      1        Alessandro D'Ausilio   \n",
       "2      2  Anderson de Souza Sant'Ana   \n",
       "3      3                 Avi Ma'ayan   \n",
       "4      4             Bonnie O'Connor   \n",
       "\n",
       "                                             ab_toks  \n",
       "0  'objectiveto', 'evalu', 'cost', 'effect', 'qua...  \n",
       "1  'test', 'whether', 'pre', 'assign', 'arm', 'mo...  \n",
       "2  'human', 'migrat', 'impli', 'adapt', 'new', 'e...  \n",
       "3  'real', 'time', 'quantit', 'pcr', 'qpcr', 'sti...  \n",
       "4  'half', 'gener', 'popul', 'attend', 'screen', ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_tok = pd.read_pickle('volume/abtokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bone, scintigraphi, wide, appli, detect, bone...\n",
       "1    [cystic, fibrosi, common, autosom, recess, dis...\n",
       "2    [alzheim, diseas, neurodegen, syndrom, charact...\n",
       "3    [purposexeroderma, pigmentosum, group, xpd, co...\n",
       "4    [class, mhc, molecul, display, peptid, cell, s...\n",
       "Name: ab_toks, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_tok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok['ab_toks'] = ab_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = df_tok.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok['ab_toks'] = df_tok['ab_toks'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok.to_sql('ed_concat_abtoks', conn, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * from ed_concat_abtoks', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ab_toks = df.ab_toks.apply(lambda x: x.replace(\"] [\",\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.editors = df.editors.apply(lambda x: x.strip('[\"]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_sql('ed_concat', conn, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ab_toks = df.ab_toks.apply(lambda x: x.strip(\"[]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>editors</th>\n",
       "      <th>ab_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alash'le G. Abimiku</td>\n",
       "      <td>'objectiveto', 'evalu', 'cost', 'effect', 'qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alessandro D'Ausilio</td>\n",
       "      <td>'test', 'whether', 'pre', 'assign', 'arm', 'mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anderson de Souza Sant'Ana</td>\n",
       "      <td>'human', 'migrat', 'impli', 'adapt', 'new', 'e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avi Ma'ayan</td>\n",
       "      <td>'real', 'time', 'quantit', 'pcr', 'qpcr', 'sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bonnie O'Connor</td>\n",
       "      <td>'half', 'gener', 'popul', 'attend', 'screen', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      editors  \\\n",
       "0         Alash'le G. Abimiku   \n",
       "1        Alessandro D'Ausilio   \n",
       "2  Anderson de Souza Sant'Ana   \n",
       "3                 Avi Ma'ayan   \n",
       "4             Bonnie O'Connor   \n",
       "\n",
       "                                             ab_toks  \n",
       "0  'objectiveto', 'evalu', 'cost', 'effect', 'qua...  \n",
       "1  'test', 'whether', 'pre', 'assign', 'arm', 'mo...  \n",
       "2  'human', 'migrat', 'impli', 'adapt', 'new', 'e...  \n",
       "3  'real', 'time', 'quantit', 'pcr', 'qpcr', 'sti...  \n",
       "4  'half', 'gener', 'popul', 'attend', 'screen', ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = df['ab_toks'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14918"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = toks[1].split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnew = []\n",
    "for line in tok:\n",
    "    l = line.replace(\"'\",\"\")\n",
    "    l = l.strip('[]')\n",
    "    tnew.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "abs_ed = []\n",
    "\n",
    "for i in range(0,len(toks)):\n",
    "    det = toks[i].replace(',','')\n",
    "    det = det.replace(\"'\",\"\")\n",
    "    det = det.strip('[]')\n",
    "    abs_ed.append(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for i in range(0,len(abs_ed)):\n",
    "    texts.append(abs_ed[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('volume2/new_models/editor_corpus.mm', corpus)\n",
    "dictionary.save('volume2/new_models/editor_dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus, normalize=True)\n",
    "tfidf.save('volume2/new_models/model.tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.491721391677856 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=50)\n",
    "lsi.save('volume2/new_models/editor_model.lsi')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 264.339075088501 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=50, passes = 4)\n",
    "lda.save('volume2/new_models/editor_model.lda')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#corpus_lda = lda[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "corpus_lda = lda[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "index.save('volume2/new_models/editor_similarity.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenizer = MosesDetokenizer()\n",
    "file = open('volume2/processed_editor_docs.txt', 'w')\n",
    "\n",
    "for i in range(0,len(texts)):\n",
    "    detok_str = detokenizer.detokenize(texts[i], return_str=True)\n",
    "    file.write(\"%s\\n\" % detok_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in TaggedLineDocument('volume2/processed_editor_docs.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 395.6190092563629 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = Doc2Vec(docs, vector_size=200, window=5, min_count=3, workers=15, epochs=20)\n",
    "\n",
    "np.save('volume2/new_models/editor_features-w2v-200.npy',model.docvecs.doctag_syn0)\n",
    "model.save('volume2/new_models/editor_features-w2v-200.doc2vec')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "notify_time": "30",
  "nteract": {
   "version": "0.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "518px",
    "left": "775px",
    "right": "31px",
    "top": "120px",
    "width": "339px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
